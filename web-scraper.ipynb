{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Selenium\n",
    "\n",
    "Below is a pipeline for scraping webpages using the Selenium WebDriver. In order to run this program, ensure that the [Chrome WebDriver](https://googlechromelabs.github.io/chrome-for-testing/) is installed.\n",
    "\n",
    "First, we import the necessary libraries and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# headless background execution\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")            # This is just to prevent Chrome from opening a window on your screen as the code runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with an example of the scraping process. Below is a link to a sample incident report. Note that the webpage containing this report is *dynamically rendered* and so the HTML cannot be scraped directly using, for example, the `requests` and `BeautifulSoup` libraries. Thus, we must render the webpage with our WebDriver in order to scrape the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.shetlandtimes.co.uk/2012/07/11/shetland-catch-ordered-to-pay-back-1-5-million-of-black-fish-profits '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the WebDriver and render the desired webpage. We then use `BeautifulSoup` to scrape the webpage and find all paragraph elements by finding all elements tagged with `<p>` and `</p>`. We can then get the text enclosed in these tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company at the heart of the black fish scam which involved thirteen Shetland fishermen and four others from the rest of Scotland was ordered to pay back £1.5 million of its illegal profits today.\n",
      "Shetland Catch was also fined £150,000 for its role in helping skippers to get round quota regulations with an elaborate and secret electronic measuring system which concealed how much fish was actually processed at its factory.\n",
      "Prosecutors had claimed that helping to land mackerel and herring which it did not declare to the authorities earned the Lerwick plant more than £6 million. Using legislation more usually directed against drug barons, the Crown demanded that the money be confiscated.\n",
      "Shetland Catch challenged the demand and Lord Turnbull heard a week of evidence and legal argument at the High Court in Edinburgh earlier this year before announcing his decision on Wednesday.\n",
      "The ruling marks the end of almost two years of argument and negotiation since August 2010 when Shetland Catch admitted its part in breaching European Union quota rules between January 2002 and March 2005.\n",
      "The firm connived with skippers on more than 700 occasions, the court heard, and during that time illegal landings of mackerel and herring – more than a third of the total – were valued at £47.5 million.\n",
      "Defence QC Murdo Macleod pleaded for leniency, pointing out the vital role Shetland Catch – one of the largest fish processors in Europe – played in the local community.\n",
      "The company had been founded in 1989 to fight off the challenge of klondyker ships from Eastern Europe, said the lawyer, and gave full-time employment to 70 people, with an extra 50 or so employed for seasonal work.\n",
      "The £3 million annual wage bill allowed workers to stay in Shetland who would otherwise have to go to the mainland.\n",
      "Shetland Catch also sponsored a scholarship in fish conservation and, since the quota offences, had played a lead role in setting up a group to ensure future sustainability of fish stocks.\n",
      "Mr Macleod also said the company had been helpless to resist the demands of the skippers, who would otherwise have gone to competitors.\n",
      "“Shetland Catch would not have survived if it refused to accept the black fish. The vessels would simply have landed elsewhere.”\n",
      "Mr Macleaod continued: “It is not putting it too strongly to say there was a position of helplessness Shetland Catch found itself in.”\n",
      "Imposing the fine, Lord Turnbull said it was right to distinguish between the company and the fishing boat masters who were landing black fish for their own financial advantage.\n",
      "The company’s co-operation with the investigation into the illegal landings – and plea of guilty – also allowed him to reduce the fine. The offence was also committed seven years ago.\n",
      "“It is perfectly obvious the present company has an approach and set of attitudes which are entirely commendable and utterly different from the circumstances which pertained in that period,” said the judge.\n",
      "Deciding the level of the £1.5 million pound confiscation order, Lord Turnbull noted that the volatile market for herring and mackerel had affected Shetland Catch which expected a loss of about £4 million during the financial year which ended in March.\n",
      "The firm had also suffered because of cuts in quotas in later years to make up for the “black fish” landings.\n",
      "Lord Turnbull said the confiscation should reflect Shetland Catch’s position in the local economy and its ability to pay.\n",
      "In a statement, Shetland Catch said the directors regretted the company’s involvement in the scam and emphasised that it had changed.\n",
      "“Long before this matter reached the court, the entire Scottish pelagic industry voluntarily agreed to participate in an unprecedented quota payback scheme whereby over quota landings were deducted from future years’ quotas,” the firm said.\n",
      "“This payback resulted in reduced raw material to the factory which was a serious challenge for our company. The financial adjustment whereby the benefit of over fishing was cancelled out by voluntary payback has been recognised by the level of confiscation order made.\n",
      "“Shetland Catch has played a crucial role in securing MSC accreditation for the entire Scottish mackerel and herring catch, proving the sustainable way these fisheries are now conducted. The contrast with the era of over quota landings of almost a decade ago cannot be over emphasised.\n",
      "“Payment for all landings of over quota fish has been made and processed through the respective seller and buyers accounts with tax paid on it.\n",
      "“Marine Scotland now has a challenge to match the responsible pelagic fishery in Scotland with the political will to preserve this economic activity for its coastal communities. The contrast with the Icelandic and Faroese governments setting their own mackerel quota for national advantage could not be more stark.\n",
      "“Today draws a line under Shetland’s involvement in this long-running investigation. We look forward anew to the forthcoming fishing seasons and thank our customers, suppliers and staff for their fortitude during this long term.”\n",
      "The town centre was a hive of activity this afternoon with Living Lerwick’s street parade the centre of attraction.\n",
      "Shetland Islands Council claims to have a grip of operations at Tingwall Airport after a chaotic spell in which air traffic was landing without paying\n",
      "The council should press ahead with statutory consultation over the proposed closure of Aith and Sandwick Junior High Schools.\n",
      "Already a subscriber? Log in below.\n",
      "Join the The Shetland Times mailing list to get one daily email update at midday on what's happening in Shetland.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(url)\n",
    "\n",
    "page_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "p_list = page_soup.find_all(\"p\")\n",
    "\n",
    "\n",
    "for p in p_list:\n",
    "    print(p.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now concatenate all of the text in the report and can optionally save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "for p in p_list:\n",
    "    text += ' ' + p.get_text()\n",
    "\n",
    "\n",
    "save_txt = False\n",
    "\n",
    "if save_txt:\n",
    "    with open(\"sample_article.txt\", \"w\") as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function summarises the above process and extracts all text from the provided url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_text(url : str, save : bool = False, file : str = '') -> str:\n",
    "    '''\n",
    "    Uses the Selenium WebDriver to scrape all text from the webpage associated to the provided url.\n",
    "\n",
    "    url : URL address for webpage to be scraped.\n",
    "    save : Optional argument for saving scraped text as a txt file.\n",
    "    file : Optional argument for naming txt file with scraped text.\n",
    "\n",
    "    Webpage text is returned as a string.\n",
    "    '''\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    page_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    p_list = page_soup.find_all(\"p\")\n",
    "\n",
    "    text = ''\n",
    "\n",
    "    for p in p_list:\n",
    "        text += ' ' + p.get_text()\n",
    "\n",
    "    if save:\n",
    "        with open(f\"{file}.txt\", \"w\") as text_file:\n",
    "            text_file.write(text)\n",
    "\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue to be aware of: The above function will scrape *all* text enclosed by paragraph tags on a webpage. This may include text that is not a part of the article, but should contain all article text. For our purposes, this should be okay since it is unlikely that any text not a part of the article will be unrelated to underreporting and misreporting fishing catches. For use with NER, especially if the NER model has been tuned, the inclusion of extra text should not be a major issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
